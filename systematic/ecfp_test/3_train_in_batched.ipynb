{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import average_precision_score\n",
    "import multiprocessing\n",
    "from tqdm.auto import tqdm\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from wandb.integration.xgboost import WandbCallback\n",
    "import os \n",
    "import re\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msavsunenko-sasha\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/anonymous/belka/systematic/ecfp_test/wandb/run-20240512_223333-k5yihchn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/savsunenko-sasha/belka/runs/k5yihchn' target=\"_blank\">unique-sun-21</a></strong> to <a href='https://wandb.ai/savsunenko-sasha/belka' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/savsunenko-sasha/belka' target=\"_blank\">https://wandb.ai/savsunenko-sasha/belka</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/savsunenko-sasha/belka/runs/k5yihchn' target=\"_blank\">https://wandb.ai/savsunenko-sasha/belka/runs/k5yihchn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='belka', tags=['xgboost'],config={\"neg_sampling_ratio\":0.15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_uuid(filename):\n",
    "    # UUID pattern: 8-4-4-4-12 hexadecimal characters\n",
    "    uuid_pattern = r'[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}'\n",
    "    \n",
    "    # Search for the UUID pattern in the filename\n",
    "    match = re.search(uuid_pattern, filename)\n",
    "    if match:\n",
    "        return match.group()  # Return the found UUID\n",
    "    else:\n",
    "        return None  # No UUID found\n",
    "    \n",
    "class Iterator(xgb.DataIter):\n",
    "  def __init__(self, prefix, directory):\n",
    "    self.prefix = prefix\n",
    "    self.directory = directory\n",
    "    self._it = 0\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.npz') and f.startswith(prefix)]\n",
    "    self.uuids = [extract_uuid(x) for x in files]\n",
    "    # XGBoost will generate some cache files under current directory with the prefix\n",
    "    # \"cache\"\n",
    "    super().__init__(cache_prefix=os.path.join(\".\", \"cache\"))\n",
    "\n",
    "  def next(self, input_data):\n",
    "    \"\"\"Advance the iterator by 1 step and pass the data to XGBoost.  This function is\n",
    "    called by XGBoost during the construction of ``DMatrix``\n",
    "\n",
    "    \"\"\"\n",
    "    if self._it == len(self.uuids):\n",
    "      # return 0 to let XGBoost know this is the end of iteration\n",
    "      return 0\n",
    "\n",
    "    # input_data is a function passed in by XGBoost who has the exact same signature of\n",
    "    # ``DMatrix``\n",
    "    file_path = os.path.join(self.directory, self.prefix+self.uuids[self._it]+'.npz')\n",
    "    matrix = sp.load_npz(file_path)\n",
    "    X = matrix\n",
    "    file_path = os.path.join(self.directory, self.prefix+self.uuids[self._it]+'.npl.npy')\n",
    "    y = np.load(file_path)\n",
    "    input_data(data=X, label=y)\n",
    "    self._it += 1\n",
    "    # Return 1 to let XGBoost know we haven't seen all the files yet.\n",
    "    return 1\n",
    "\n",
    "  def reset(self):\n",
    "    \"\"\"Reset the iterator to its beginning\"\"\"\n",
    "    self._it = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_micro(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    # Calculate the MAP score\n",
    "    score = average_precision_score(labels, preds, average='micro')\n",
    "    return 'map_micro', score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(Iterator(prefix = \"train_\", directory='/mnt/fastssd/belka_data/train_split_test/'))\n",
    "dtest_random = xgb.DMatrix(Iterator(prefix = \"random_test_\", directory='/mnt/fastssd/belka_data/train_split_test/'))\n",
    "dtest_unique = xgb.DMatrix(Iterator(prefix = \"unique_test_\", directory='/mnt/fastssd/belka_data/train_split_test/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:35:45] INFO: /home/conda/feedstock_root/build_artifacts/xgboost-split_1713397827678/work/src/data/./sparse_page_dmatrix.h:147: Make cache:./cache-0x5e56989aca50.ellpack.page\n",
      "\n",
      "[22:35:45] INFO: /home/conda/feedstock_root/build_artifacts/xgboost-split_1713397827678/work/src/data/./sparse_page_dmatrix.h:147: Make cache:./cache-0x5e56989aca50.ellpack.page\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'device': 'cuda',\n",
    "    'subsample': 0.3,\n",
    "    'sampling_method': 'gradient_based',\n",
    "    'tree_method': 'hist',  # Utilize GPU for histogram construction\n",
    "    'learning_rate': 0.03,\n",
    "    'max_depth': 6,\n",
    "    'n_jobs': multiprocessing.cpu_count(),\n",
    "    'min_child_weight': 1,\n",
    "    # 'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'verbosity': 2,\n",
    "}\n",
    "evals_result_unique = {}\n",
    "model = xgb.train(params, dtrain, evals=[(dtrain, 'train'), (dtest_random, 'test_random'), (dtest_unique, 'test_unique')], \n",
    "                  num_boost_round=1, early_stopping_rounds=20,\n",
    "                  evals_result=evals_result_unique, custom_metric=map_micro,\n",
    "                  maximize=True, callbacks=[WandbCallback(log_model=True)])  # Since MAP is higher the better\n",
    "model.save_model('unique_best.xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WandbCallback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 21\u001b[0m\n\u001b[1;32m      2\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_metric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     16\u001b[0m }\n\u001b[1;32m     17\u001b[0m evals_result_random \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mtrain(params, dtrain, evals\u001b[38;5;241m=\u001b[39m[(dtrain, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m), (dtest_unique, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_unique\u001b[39m\u001b[38;5;124m'\u001b[39m),  (dtest_random, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_random\u001b[39m\u001b[38;5;124m'\u001b[39m),], \n\u001b[1;32m     19\u001b[0m                   num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000000\u001b[39m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     20\u001b[0m                   evals_result\u001b[38;5;241m=\u001b[39mevals_result_random, custom_metric\u001b[38;5;241m=\u001b[39mmap_micro,\n\u001b[0;32m---> 21\u001b[0m                   maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m[\u001b[43mWandbCallback\u001b[49m(log_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)])  \u001b[38;5;66;03m# Since MAP is higher the better\u001b[39;00m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_random.xgb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'WandbCallback' is not defined"
     ]
    }
   ],
   "source": [
    "# Parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'device': 'cuda',\n",
    "    'subsample': 0.3,\n",
    "    'sampling_method': 'gradient_based',\n",
    "    'tree_method': 'hist',  # Utilize GPU for histogram construction\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'n_jobs': multiprocessing.cpu_count(),\n",
    "    'min_child_weight': 1,\n",
    "    # 'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'verbosity': 2,\n",
    "}\n",
    "evals_result_random = {}\n",
    "model = xgb.train(params, dtrain, evals=[(dtrain, 'train'), (dtest_unique, 'test_unique'),  (dtest_random, 'test_random'),], \n",
    "                  num_boost_round=1000000, early_stopping_rounds=10,\n",
    "                  evals_result=evals_result_random, custom_metric=map_micro,\n",
    "                  maximize=True, callbacks=[WandbCallback(log_model=True)])  # Since MAP is higher the better\n",
    "model.save_model('unique_random.xgb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
