{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['belka']  # Replace with your database name\n",
    "collection = db['train_metadata']  # Replace with your collection name\n",
    "\n",
    "\n",
    "# Using the aggregation framework to get N random documents\n",
    "random_documents = list(collection.aggregate([\n",
    "    {'$project': {'molecule_smiles': 1, 'binds': 1, 'protein_name':1,'_id': 0 ,'test_u':1, 'test1':1, 'test2':1}}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anonymous/miniconda3/envs/belka/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_documents = pd.DataFrame(random_documents)\n",
    "unique_smiles = random_documents['molecule_smiles'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199/199 [11:39<00:00,  3.51s/it]\n"
     ]
    }
   ],
   "source": [
    "db = client['belka']  # Replace with your database name\n",
    "collection = db['full_molecules']  # Replace with your collection name\n",
    "\n",
    "# The field you want to retrieve, and assuming '_id' is not needed\n",
    "projection = {'Avalon': 1, 'Torsion':1, 'RDKFingerprint':1, 'maccs':1, 'ecfp':1, 'molecular_size':1, 'molecule_smiles':1, '_id': 0}  # Adjust 'needed_field' to your specific field name\n",
    "# Define batch size\n",
    "batch_size = 10000\n",
    "current_skip = 0\n",
    "documents = []\n",
    "\n",
    "# Properly manage range for unique_smiles slicing\n",
    "steps = len(unique_smiles) // batch_size + (1 if len(unique_smiles) % batch_size != 0 else 0)\n",
    "\n",
    "# Using tqdm to iterate over the batches\n",
    "for i in tqdm(range(steps)):\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + batch_size\n",
    "    batch_query = unique_smiles[start_index:end_index]\n",
    "    batch_docs = list(collection.find({'molecule_smiles': {'$in': list(batch_query)}}, projection))\n",
    "    if not batch_docs:  # Check if the fetched batch is empty\n",
    "        break\n",
    "    documents.extend(batch_docs)\n",
    "\n",
    "# Convert results to a Pandas DataFrame\n",
    "df = pd.DataFrame(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anonymous/miniconda3/envs/belka/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Step 1: Merge DataFrames\n",
    "merged_df = pd.merge(random_documents, df, on='molecule_smiles', how='inner')\n",
    "\n",
    "# Step 2: One-Hot Encoding for protein_name\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoded = encoder.fit_transform(merged_df[['protein_name']])\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(['protein_name']))\n",
    "merged_df = pd.concat([merged_df, one_hot_df], axis=1).drop('protein_name', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_parquet('training_all_fingers_set.parquet', engine='pyarrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
